{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Multivariate analysis\n",
    "\n",
    "For this exercise we recommend using [SciKit-Learn](https://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning for the $\\tau^-\\to\\mu^-\\mu^+\\mu^-$ search at LHCb\n",
    "\n",
    "The LHCb experiment at CERN is able to search for exotic decays of the $\\tau$ lepton to three muons. This process is fobidden in the Standard Model but is predicted to be sizeable in several theories beyond the Standard Model.\n",
    "\n",
    "Your goal is to maximise the chances to find this decay in the dataset collected by LHCb using a Machine Learning technique to classify the recorded events as signal or background.\n",
    "\n",
    "You are given a dataset composed of labelled signal (`signal==1`) and background (`signal==0`) events. Each event is described by a set of *features* whose distribution might be different between signal and background. The goal is to train a Machine Learning classifier to guess if an event is signal or background based on these features.\n",
    "\n",
    "Here's the list of features recorded in the dataset that you can use for the classification:\n",
    "* `DecayTime` - How long the $\\tau$ candidate existed before decaying.\n",
    "* `IP` - [Impact parameter](https://en.wikipedia.org/wiki/Impact_parameter) of the $\\tau$ candidate and the collision point.\n",
    "* `VertexChi2` - The $\\chi^2$ of a fit to locate the $\\tau$ decay vertex.\n",
    "* `pt` - Transverse momentum of the $\\tau$.\n",
    "* `DOCAone` - Distance of closest approach between first and second muons.\n",
    "* `DOCAtwo` - Distance of closest approach between second and third muons.\n",
    "* `DOCAthree` - Distance of closest approach between first and third muons.\n",
    "* `isolationa` - Track isolation variable.\n",
    "* `isolationb` - Track isolation variable.\n",
    "* `isolationc` - Track isolation variable.\n",
    "* `p0_pt` - Transverse momentum of the first muon.\n",
    "* `p1_pt` - Transverse momentum of the second muon.\n",
    "* `p2_pt` - Transverse momentum of the third muon.\n",
    "* `p0_IP` - Impact parameter of the first muon.\n",
    "* `p1_IP` - Impact parameter of the second muon.\n",
    "* `p2_IP` - Impact parameter of the third muon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_csv('training_reduced.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate the [Kolmogorov-Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test) between signal and background for each of the features of the dataset. The test evaluates how likely are two data samples to be drawn from the same PDF, and therefore should be larger for the features that are most powerful to discriminate signal and background.\n",
    "\n",
    "*Hint:* you can use the [`ks_2samp` function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html) from `scipy.stats` to compute the Kolmogorov-Smirnov test between two samples\n",
    "\n",
    "*Hint:* you can get the list of features from the DataFrame column headings, i.e. `d.keys()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KstestResult(statistic=1.0, pvalue=0.0)\n",
      "KstestResult(statistic=0.14423987132737376, pvalue=2.5633875826106553e-290)\n",
      "KstestResult(statistic=0.5503323429451006, pvalue=0.0)\n",
      "KstestResult(statistic=0.28567312506181025, pvalue=0.0)\n",
      "KstestResult(statistic=0.1377976891036844, pvalue=6.7965246029508e-265)\n",
      "KstestResult(statistic=0.15488706886849868, pvalue=0.0)\n",
      "KstestResult(statistic=0.15537702908242712, pvalue=0.0)\n",
      "KstestResult(statistic=0.14469064866972225, pvalue=3.8510728182137147e-292)\n",
      "KstestResult(statistic=0.24067798381021005, pvalue=0.0)\n",
      "KstestResult(statistic=0.16782063583131873, pvalue=0.0)\n",
      "KstestResult(statistic=0.1686414213935396, pvalue=0.0)\n",
      "KstestResult(statistic=0.10270530235899855, pvalue=4.5061441238451737e-147)\n",
      "KstestResult(statistic=0.1370815349196095, pvalue=3.850658338917715e-262)\n",
      "KstestResult(statistic=0.039081124813342416, pvalue=1.2683241258042925e-21)\n",
      "KstestResult(statistic=0.1283789911393617, pvalue=7.5456630574203215e-230)\n",
      "KstestResult(statistic=0.01844486715444149, pvalue=3.7814198569140285e-05)\n",
      "KstestResult(statistic=0.023197690690730743, pvalue=6.779898240186799e-08)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "#help(ks_2samp)\n",
    "keys = d.keys()\n",
    "for key in keys:\n",
    "    # print(d[key][d[\"signal\"] == 0])\n",
    "    print(ks_2samp(d[key][d[\"signal\"] == 0], d[key][d[\"signal\"] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The least and most discriminating features are the ones with the lowest and highest Kolmogorov-Smirnov scores, respectively. Compare the signal and background distributions for these two features.\n",
    "\n",
    "**NB:** please do not use the label `signal` as a feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split the dataset *randomly* in two halves: we will use one half for training our classifier and the other half to test it.\n",
    "\n",
    "*Hint:* you can use the function `train_test_split` from `sklearn.model_selection`\n",
    "\n",
    "**NB:** the dataset is ordered by `signal`, hence the need for random splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(d.drop(\"signal\", axis=1), d[\"signal\"], test_size = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\n",
    "\n",
    "i. Train a [Gaussian naive Bayes classifier](https://scikit-learn.org/stable/modules/naive_bayes.html) on the training sample using the three features of your choice (possibly the most discriminant ones). You can use [`GaussianNB` from `sklearn.naive_bayes`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Now train a [gradient-boosted decision tree (GBDT)](https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting) on the training sample using the same three features. You can use [`GradientBoostingClassifier` from `sklearn.ensemble`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate the classifier responses on both the training and testing samples and overlay histograms of the response for signal and background.\n",
    "\n",
    "*Hint:* to evaluate the response use `gbdt.decision_function()` and `gnb.predict_proba()`\n",
    "\n",
    "*Hint:* the `predict_proba()` function will return a 2D array: background & signal probabilities for each point in the sample. You can call `predict_proba(...)[:,0]` or `predict_proba(...)[:,1]` to obtain just the signal score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Check if there is overtraining by performing a Kolmogorov-Smirnov test on the classifier responses between the training and testing sample. If you did not overtrain the classifier, its response should be the same on the training and testing samples both for signal and for background. Therefore the K-S scores should be small (~0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Show the performance of your classifiers with a ROC curve. Plot the ROC curves on the same plot and label the axes.\n",
    "\n",
    "*Hint:* you can use the function `roc_curve` from `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "#help(roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**: Try to improve the performance of your classifier by including more features and changing the initialisation options of the `GradientBoostingClassifier` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
